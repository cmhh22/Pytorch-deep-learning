# ðŸ§  CNN Transfer Learning with EfficientNet-B0

[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Educational project** demonstrating **transfer learning** with a state-of-the-art CNN architecture on the CIFAR-10 dataset.

---

## ðŸ“š Table of Contents

- [Overview](#-overview)
- [What is Transfer Learning?](#-what-is-transfer-learning)
- [EfficientNet Architecture](#-efficientnet-architecture)
- [Dataset: CIFAR-10](#-dataset-cifar-10)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Learning Guide](#-learning-guide)
- [Results](#-results)
- [References](#-references)

---

## ðŸŽ¯ Overview

This project teaches you how to:

1. **Use a pretrained CNN** (EfficientNet-B0) for a new classification task
2. **Fine-tune vs Feature Extraction** â€” two transfer learning strategies
3. **Implement a complete training pipeline** with PyTorch
4. **Analyze model performance** with confusion matrices and Grad-CAM

### Why This Project?

| Skill | What You'll Learn |
|-------|-------------------|
| ðŸ—ï¸ Architecture | How modern CNNs (EfficientNet) are structured |
| ðŸ”„ Transfer Learning | Reuse ImageNet features for new tasks |
| ðŸ“Š Evaluation | Confusion matrix, per-class metrics, error analysis |
| ðŸ” Interpretability | Grad-CAM to visualize what the model "sees" |

---

## ðŸ”„ What is Transfer Learning?

**Transfer learning** means taking a model trained on one task and adapting it to a different task.

### The Intuition

Imagine you learned to play piano. When you try to learn guitar, you don't start from zero â€” you already understand music theory, rhythm, and hand coordination. Transfer learning works the same way for neural networks!

### How It Works

```
ImageNet (1.2M images, 1000 classes)
         â†“
    Pretrained CNN
    (learned general features: edges, textures, shapes)
         â†“
    Replace final layer
    (1000 classes â†’ 10 classes for CIFAR-10)
         â†“
    Fine-tune on new dataset
```

### Two Strategies

| Strategy | Description | When to Use |
|----------|-------------|-------------|
| **Feature Extraction** | Freeze backbone, train only classifier | Small dataset, limited compute |
| **Fine-Tuning** | Train all layers (smaller learning rate) | More data, need higher accuracy |

In this project, use `--freeze-backbone` for feature extraction or omit it for fine-tuning.

---

## ðŸ›ï¸ EfficientNet Architecture

**EfficientNet** was developed by Google in 2019 and achieves state-of-the-art accuracy with fewer parameters than previous architectures.

### Key Innovation: Compound Scaling

Previous CNNs scaled only one dimension (depth OR width OR resolution). EfficientNet scales all three together using a compound coefficient:

```
depth:      d = Î±^Ï†
width:      w = Î²^Ï†  
resolution: r = Î³^Ï†

where Î±Â·Î²Â²Â·Î³Â² â‰ˆ 2 (to roughly double FLOPs)
```

### EfficientNet Family

| Model | Parameters | Top-1 Acc (ImageNet) | Input Size |
|-------|------------|----------------------|------------|
| **B0** | 5.3M | 77.1% | 224Ã—224 |
| B1 | 7.8M | 79.1% | 240Ã—240 |
| B2 | 9.2M | 80.1% | 260Ã—260 |
| B3 | 12M | 81.6% | 300Ã—300 |
| B7 | 66M | 84.3% | 600Ã—600 |

We use **B0** because it's lightweight and perfect for learning!

### Architecture Diagram

```
Input (224Ã—224Ã—3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stem: Conv3Ã—3 + BatchNorm + SiLU   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MBConv Blocks (Ã—16)                â”‚
â”‚  - Depthwise Separable Convolution  â”‚
â”‚  - Squeeze-and-Excitation (SE)      â”‚
â”‚  - Skip connections                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Head: Conv1Ã—1 + GlobalAvgPool      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Classifier: Dropout + Linear       â”‚  â† We replace this!
â”‚  (1280 â†’ 10 classes)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output (10 class probabilities)
```

---

## ðŸ“¦ Dataset: CIFAR-10

### Overview

| Property | Value |
|----------|-------|
| **Images** | 60,000 color images |
| **Size** | 32Ã—32 pixels (we resize to 224Ã—224) |
| **Classes** | 10 |
| **Train/Test** | 50,000 / 10,000 |
| **Balance** | Perfectly balanced (6,000 per class) |

### Classes

| Label | Class | Label | Class |
|-------|-------|-------|-------|
| 0 | âœˆï¸ Airplane | 5 | ðŸ• Dog |
| 1 | ðŸš— Automobile | 6 | ðŸ¸ Frog |
| 2 | ðŸ¦ Bird | 7 | ðŸ´ Horse |
| 3 | ðŸ± Cat | 8 | ðŸš¢ Ship |
| 4 | ðŸ¦Œ Deer | 9 | ðŸšš Truck |

### Where to Download?

**You don't need to download manually!** ðŸŽ‰

The dataset is automatically downloaded by `torchvision` when you run training:

```python
from torchvision import datasets
datasets.CIFAR10(root='data', train=True, download=True)
```

Files are saved to:
```
data/
â””â”€â”€ cifar-10-batches-py/
    â”œâ”€â”€ data_batch_1
    â”œâ”€â”€ data_batch_2
    â”œâ”€â”€ data_batch_3
    â”œâ”€â”€ data_batch_4
    â”œâ”€â”€ data_batch_5
    â”œâ”€â”€ test_batch
    â”œâ”€â”€ batches.meta
    â””â”€â”€ readme.html
```

**Manual download** (if needed): https://www.cs.toronto.edu/~kriz/cifar.html

---

## ðŸ“ Project Structure

```
cnn-efficientnet/
â”œâ”€â”€ main.py              # ðŸš€ CLI entry point (train/eval commands)
â”œâ”€â”€ test_quick.py        # ðŸ§ª Smoke test (verify everything works)
â”œâ”€â”€ requirements.txt     # ðŸ“¦ Dependencies
â”œâ”€â”€ README.md            # ðŸ“– This file
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ model.py         # ðŸ—ï¸ EfficientNet builder + transfer learning config
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data.py          # ðŸ“Š CIFAR-10 loaders + augmentation
â”‚   â”œâ”€â”€ engine.py        # ðŸ”„ Training and evaluation loops
â”‚   â””â”€â”€ utils.py         # ðŸ› ï¸ Checkpoints, metrics, reproducibility
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ train_colab.ipynb            # ðŸš€ Training notebook (Google Colab GPU)
â”‚   â””â”€â”€ analysis_post_training.ipynb # ðŸ“ˆ Confusion matrix + Grad-CAM
â”‚
â””â”€â”€ data/                # ðŸ“‚ CIFAR-10 (auto-downloaded)
```

---

## âš™ï¸ Installation

### Prerequisites
- Python 3.8+
- pip or conda

### Setup

```bash
# 1. Clone or navigate to the project
cd cnn-efficientnet

# 2. Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# 3. Install dependencies
pip install -r requirements.txt
```

### Dependencies

```
torch>=2.2          # Deep learning framework
torchvision>=0.17   # Pretrained models + datasets
numpy>=1.24         # Numerical computing
tqdm>=4.66          # Progress bars
```

For the analysis notebook, also install:
```bash
pip install matplotlib seaborn scikit-learn
```

---

## ðŸš€ Usage

### Quick Test (Verify Setup)

```bash
python test_quick.py
```

Expected output:
```
âœ“ Quick train OK | loss=X.XXXX acc=X.XXXX
All components working correctly!
```

### Train Model

**Feature Extraction** (fast, ~90% accuracy):
```bash
python main.py train --epochs 5 --freeze-backbone
```

**Fine-Tuning** (slower, higher accuracy):
```bash
python main.py train --epochs 10 --lr 1e-4
```

**Full options**:
```bash
python main.py train \
    --epochs 10 \
    --batch-size 64 \
    --lr 3e-4 \
    --weight-decay 1e-4 \
    --freeze-backbone \
    --scheduler cosine \
    --patience 5 \
    --out models/my_model.pth
```

**Advanced options**:
| Option | Default | Description |
|--------|---------|-------------|
| `--scheduler` | `cosine` | Learning rate scheduler: `cosine`, `plateau`, or `none` |
| `--patience` | `5` | Early stopping patience (epochs without improvement) |
| `--no-early-stop` | `False` | Disable early stopping |

### Evaluate Model

```bash
python main.py eval --checkpoint models/efficientnet_cifar10_best.pth
```

### Run Analysis Notebook

```bash
jupyter notebook notebooks/analysis_post_training.ipynb
```

### ðŸš€ Train on Google Colab (Recommended for GPU)

If you don't have a dedicated NVIDIA GPU, use Google Colab for faster training:

1. Open [`notebooks/train_colab.ipynb`](notebooks/train_colab.ipynb) in Google Colab
2. Go to **Runtime > Change runtime type > GPU**
3. Run all cells

**Expected speedup: ~40x faster than CPU!**

| Environment | Time per Epoch |
|-------------|----------------|
| CPU (Intel i5) | ~50 minutes |
| GPU (Colab T4) | ~1-2 minutes |

---

## ðŸ“– Learning Guide

### Recommended Learning Path

1. **Read this README** â€” Understand the concepts
2. **Run `test_quick.py`** â€” See the pipeline in action
3. **Read `models/model.py`** â€” Understand transfer learning setup
4. **Read `src/data.py`** â€” Learn about data augmentation
5. **Read `src/engine.py`** â€” Study the training loop
6. **Train a model** â€” Experiment with hyperparameters
7. **Run the notebook** â€” Analyze your trained model

### Key Concepts to Understand

| Concept | File | Lines to Study |
|---------|------|----------------|
| Transfer learning setup | `models/model.py` | `build_efficientnet_b0()` |
| Freezing layers | `models/model.py` | `set_trainable()` |
| Data augmentation | `src/data.py` | `build_transforms()` |
| ImageNet normalization | `src/data.py` | `Normalize(mean, std)` |
| Training loop | `src/engine.py` | `train_one_epoch()` |
| Evaluation mode | `src/engine.py` | `model.eval()` |

### Experiments to Try

1. **Compare strategies**: Train with and without `--freeze-backbone`
2. **Learning rate**: Try `1e-3`, `3e-4`, `1e-4`, `1e-5`
3. **Batch size**: Compare `32` vs `64` vs `128`
4. **Epochs**: Watch for overfitting with more epochs
5. **Augmentation**: Modify `build_transforms()` in `src/data.py`

---

## ðŸ“Š Results

### Expected Performance

| Strategy | Epochs | Val Accuracy | Training Time* |
|----------|--------|--------------|----------------|
| Feature Extraction | 5 | ~85-90% | ~5 min (GPU) |
| Fine-Tuning | 10 | ~92-95% | ~15 min (GPU) |

*On NVIDIA RTX 3060 or similar

### Sample Training Output

```
Using device: cuda
Train batches: 782, Val batches: 157
Trainable parameters: 12,810 (freeze) or 4,020,618 (full)

Epoch 01/05 | Train Loss: 0.8234, Acc: 0.7123 | Val Loss: 0.4521, Acc: 0.8456
  â†³ New best model saved! (acc=0.8456)
Epoch 02/05 | Train Loss: 0.4123, Acc: 0.8567 | Val Loss: 0.3892, Acc: 0.8721
  â†³ New best model saved! (acc=0.8721)
...
Training complete! Best validation accuracy: 0.8912
```

---

## ðŸ“š References

### Papers

1. **EfficientNet**: Tan & Le (2019). "EfficientNet: Rethinking Model Scaling for CNNs" 
   - [arXiv:1905.11946](https://arxiv.org/abs/1905.11946)

2. **CIFAR-10**: Krizhevsky (2009). "Learning Multiple Layers of Features from Tiny Images"
   - [Technical Report](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)

3. **Grad-CAM**: Selvaraju et al. (2017). "Grad-CAM: Visual Explanations from Deep Networks"
   - [arXiv:1610.02391](https://arxiv.org/abs/1610.02391)

### Tutorials

- [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [EfficientNet in TorchVision](https://pytorch.org/vision/stable/models/efficientnet.html)

---

## ðŸ“„ License

MIT License â€” feel free to use this project for learning!

---

<div align="center">

*Part of the `pytorch-deep-learning` portfolio series*

</div>
